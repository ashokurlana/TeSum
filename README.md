## Telugu Abstractive Summarization
This repository contain TeSum dataset and benchmark models implementation for Telugu language.


### Step 1 Download the data
Download the TeSum dataset from ```tesum_data``` directory


## Benchmark Models for Telugu Abstractive Summarization

#### Pointer_Generator : [ Get To The Point: Summarization with Pointer-Generator Networks ](https://arxiv.org/pdf/1704.04368.pdf)
#### ML_RL: [A Deep Reinforced Model For Abstractive Summarization ](https://arxiv.org/pdf/1705.04304.pdf)
#### BERTSum : [Text Summarization with Pretrained Encoders](https://arxiv.org/pdf/1908.08345.pdf)
#### mT5 : [XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages](https://aclanthology.org/2021.findings-acl.413.pdf)
#### mBART50 : [Multilingual Translation with Extensible Multilingual Pretraining and Finetuning](https://arxiv.org/pdf/2008.00401.pdf)



You can see the individual directories for above mentioned models. Go to the respective model directory and follow the corresponding instructions to setup the models.

##### Note:  All the experiments were performed on a single NVIDIA GeForce GTX 1080 GPU.

	
